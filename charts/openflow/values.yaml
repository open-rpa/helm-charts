NODE_ENV: production
domainsuffix:
domain:
apidomain:
protocol: http # set the https if using tlsSecret or certresolver
traefik: 
  # IngressRouteApiVersion: traefik.containo.us/v1alpha1
  IngressRouteApiVersion: traefik.io/v1alpha1
certificate:
  create: false # Create a certificate, when using certificate manager
  tlsSecret: # Add tlsSecret to all ingress controllers, handy if using certificate manager, or you imported your own certificate in a secret
  certresolver: # if you have added a certificate resolver to traefik, set it here also
  certmain: # to predefine certificate name, set this, usefull if using wildcard certificates, for instance: demo.openiap.io
  certsans: # set subjecter alternative names in the certificate. for instance: *.demo.openiap.io
nodeSelector: {} # remeber to set under mongodb too
imagePullSecrets: 
port: # if the external port to access this is differente from 80/443, then set this the port users will access this instance on
grpc:
  exposed: false
  internalport: 50051
redis:
  # enabled: true # set using openflow.cache_store_type "redis"
  # image: redis # set using image: {{ .Values.openflow.redisimage | quote }}
  resources: {}
openflow:
  image: openiap/openflow # set image for api deployment
  node_options: # --max_old_space_size=2048 / On a machine with 2GB of memory, consider setting this to 1536 (1.5GB)
  prestop:
    enabled: false
    command: "wget http://localhost:3000/heapdump"
  disable_db_config: # Disable loading config from database, default false
  use_openshift_routes: 
  terminationGracePeriodSeconds: 15
  deploymentstrategy: RollingUpdate # Recreate or RollingUpdate
  sessionAffinity: None # either None or ClientIP. Set to ClientIP to use sticky sessions ( clients will always hit the same pod, based on number of pods and client ip )
  agent_images:
  saml_issuer:

  # What url to show inside the robot's getting started page
  replicas: 1 # number of api pods to spin up
  # This is the max unavailable setting for the pod disruption budget
  # The default value of 1 will make sure that kubernetes won't allow more than 1
  # of your pods to be unavailable during maintenance
  maxUnavailable: 1

  port: 3000 # pod/deployment will use this port
  cache_store_type: memory # memory or redis
  redisimage: redis
  cache_store_ttl_seconds: # Items expire from store after this amount of seconds
  cache_store_max: # Max items to store when using memory store
  cache_store_redis_password: # When store type is "redis" use this password for redis
  livenessProbe:
    enabled: true
    path: /livenessprobe
    initialDelaySeconds: 10
    periodSeconds: 2
    failureThreshold: 3
    timeoutSeconds: 5
  readinessProbe:
    enabled: true
    path: /livenessprobe
    initialDelaySeconds: 2
    periodSeconds: 2
    failureThreshold: 3
    timeoutSeconds: 5
  startupProbe:
    enabled: false
    path: /livenessprobe
    initialDelaySeconds: 2
    periodSeconds: 2
    failureThreshold: 3
    timeoutSeconds: 5
  enable_openapiauth: # Force user authentication to use openai plugin ( without will allows ADMIN access to the database, for tesing ONLY !!!! )
  auto_create_users: # if trying to login using unknown username, auto create it ?
  auto_create_domains: # limit auto created logins to emails using these domains, seperated by comma ,
  auto_create_personal_nodered_group: # to avoid users getting access denied first time creating nodered, pre-create the role and make user member of the role
  auto_create_personal_noderedapi_group: # Auto create the role used for api access to users personal nodered
  # allow api node to listen on https, not recomended in docker, use a reverse proxy instead
  multi_tenant: # if multi tenant is enabled, will lock down default roles to avoid users can "see each other" any custom roles created will allow users of same role to see each other
  amqp_enabled_exchange:  # enabled the amp exchange node in nodered, and enabled Register Exchange command in API

  use_ingress_beta1_syntax: # Use beta one syntax for ingress controller, default: false
  traefik_ipblock: false # Tell traefic to check IP before forwarding request, using OpenFlow blocklist endpoint

  # The SAML Provider need to sign all tokens issued, use this certificate to sign SAML tokens
  signing_crt: LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSURqRENDQW5TZ0F3SUJBZ0lKQUp5N0tIMTE1dkQ4TUEwR0NTcUdTSWIzRFFFQkN3VUFNRnN4Q3pBSkJnTlYKQkFZVEFrUkxNUk13RVFZRFZRUUlEQXBUYjIxbExWTjBZWFJsTVNFd0h3WURWUVFLREJoSmJuUmxjbTVsZENCWAphV1JuYVhSeklGQjBlU0JNZEdReEZEQVNCZ05WQkFNTUMzTnBaMjVwYm1kalpYSjBNQjRYRFRFNU1EUXdOekUwCk5ETXpORm9YRFRJNU1EUXdOREUwTkRNek5Gb3dXekVMTUFrR0ExVUVCaE1DUkVzeEV6QVJCZ05WQkFnTUNsTnYKYldVdFUzUmhkR1V4SVRBZkJnTlZCQW9NR0VsdWRHVnlibVYwSUZkcFpHZHBkSE1nVUhSNUlFeDBaREVVTUJJRwpBMVVFQXd3TGMybG5ibWx1WjJObGNuUXdnZ0VpTUEwR0NTcUdTSWIzRFFFQkFRVUFBNElCRHdBd2dnRUtBb0lCCkFRQy9JSkdEaGxLTU9SWkoycXQwSWpjSDZOWUFtZDVxQzQ4dkNJRE54QWZCbmQxQnN4WlVjWkl5dkFlT28yNDcKM3I0eTYwNDgxRHVUS2JaMTBTNjRqRU05aW1XTXB1TFlJRnVyQ3BWNzVEWWhxMS85Q0FJVHJqNjlmVDluSkptcwpjM2lxTnJ1Tlg1bDlISXdadWtQM1ZNRkJRNWZVd3N1ZnE0YW1NbnVnZmtyUEVzSngxK3VJb0NYU3pyblZvcnZpClZ0ZFh4a3M4N0l1S0ZnMDJIZ1RQSzdwc0FXYTBRY3g2ck04bkV5TUhwNUdlR1Rvb1NNbkcyZ1RGNWZOSVFNdTMKVEVoc2p3SWRTYmRwck1Gb1VZV05Bc2FueTJOQk0wREhZRUdjQlZhZ0xWNUhFUW5ySUM3NEhtNjYxdG9HaU5VSAoveW04U3VndTgwWVFiVGxPcTFWNnNkaVRBZ01CQUFHalV6QlJNQjBHQTFVZERnUVdCQlMrYWc1NGtITllKZ29pCm9yRnlia293THR5R3ZqQWZCZ05WSFNNRUdEQVdnQlMrYWc1NGtITllKZ29pb3JGeWJrb3dMdHlHdmpBUEJnTlYKSFJNQkFmOEVCVEFEQVFIL01BMEdDU3FHU0liM0RRRUJDd1VBQTRJQkFRQTZpZHBYdzdSR2pzcUpNanI2c1YvaQpXeXFsL2xkSy9sa1NCdnNBSENieDdQYi9rVUd2NHJNbndYMnBHdTR0YkFnSDc4eStmS3dzazllYkxDeTA4Y1k0Ckt5czhzbUpLenhWN0R6U3RVR1NvZmZMaFliVVVMK3UyNU5vVXc0TG1WQU5FU0NaMTZ3aTdPQUdJMkJnNFR6TXoKdnlIUHRaaE9wTXBNV2lzM2ZnRXFzV3QxS2VLcXo0Z2M5RnJtZDZPNlQzVVAxWTRBR3VEWnNScnpiU2RQS2JxbApxekprT2tQcGtHOGo3ZjFWNkk1ZlkzblZaSWk2YW1TcTM1RTJkQzVMY0dIQXRtT1lWL0c4TEQ3OUFnTVpFUU5vCkF2R2RnV1gvbXBFVkFjMmRFQkJlcUN6WjF1aVhWUjdERld2ZDFKTEpsdVRyTm9jMUROc0xNKzNEZFFiQ2JnYVcKLS0tLS1FTkQgQ0VSVElGSUNBVEUtLS0tLQo=
  singing_key: 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
  # To enable enterprise features, add your licanse key here
  license_key:
  license_private_key:
  # if not using helm to deploy mongodb, set this to the connection string of your mongodb
  external_mongodb_url:
  # if not using helm to deploy mongodb, set your desired database to use
  mongodb_db:
  # enable email validation of all non-federated users, require smtp settings to bet set
  validate_emails: 
  # enable "forgot password" by email validation for non-federated users, require smtp settings to bet set
  forgot_pass_emails:
  # when validating email, check if disposable email, using https://debounce.io/free-disposable-check-api/
  validate_emails_disposable: 
  # Node mailer, service type
  smtp_service: 
  # When sending service mails, sent from this email
  smtp_from: 
  # Username when sending ( smtp service=gmail for everything else, use smtp_url )
  smtp_user: 
  # password when sending ( smtp service=gmail for everything else, use smtp_url )
  smtp_pass: 
  # Use smtp url for configuration  ( see https://nodemailer.com/smtp/ or https://www.npmjs.com/package/nodemailer/v/2.2.0-beta.0 ) 
  smtp_url: 
  # To override the default minPoolSize of the database connection, usefull when needing a lot of watches or have many clients
  mongodb_minpoolsize:
  # To override the default maxPoolSize of the database connection, usefull when needing a lot of watches or have many clients
  mongodb_maxpoolsize:
  # Auto-create default indexes doing startup, default: true
  ensure_indexes:
  metadata_collections: # List of timeserie collections that uses metadata
  # openflow will keep track of all changes on all documents except inside these collections
  enable_openflow_amqp: 
  openflow_amqp_expiration: # messages send to backend expire after this amount of time. default: 25 min
  amqp_prefetch: # each api instance allows only this amount of message to be processed at the same time, default 50
  enable_entity_restriction: # Add restrictions on who can create entities in different collections, default false
  enable_web_tours: # Enable tours and notification about new features inside openflow
  enable_nodered_tours: # Enable tours and notification about new features inside NodeRED
  grafana_url:  # add grafana link in main menu
  ping_clients_interval: # each api node pings connected clients witht his interval, and update the user object for each online user

  # Use an dedicated message queue for distributing messages among all api instances ( to load balending trafic more evenly )
  skip_history_collections: 
  history_delta_count: # default 1000
  oidc_access_token_ttl: 

  # To allow buying addon products or dedicated nodered instance, add stripe api key and secret
  stripe_api_key:
  stripe_api_secret:
  api_rate_limit: # to disable rate limits on all http requests, set this to false
  api_rate_limit_points: # to change the amount of points a hit consume, default: 1
  api_rate_limit_duration: # to change how long it takes for a point to expire in seconds, default: 60
  socket_rate_limit: # to disable rate limits on socket messages, set this to false
  socket_rate_limit_points: # to change the amount of points a hit consume, default: 1
  socket_rate_limit_duration: # to change how long it takes for a point to expire in seconds, default: 30
  socket_rate_limit_points_disconnect: # If client builds up this amount of points, disconnect the client, default: 600
  client_heartbeat_timeout: # Disconnect clients who has not send any messages after this many seconds, default: 60
  client_signin_timeout: # Disconnect clients who has not signed in after this many seconds, default: 120

  aes_secret: # use this to encrypt parts of mongodb documents and hash user passwords
  resources: {}
  api_ws_url: # force new nodereds and browser to use this url to access the api
  saml_federation_metadata: # Override SAML url for new nodered instances
  enable_analytics: # Enable analytics
  otel_trace_url: # Open Telemetry exporter trace URL
  otel_metric_url: # Open Telemetry exporter metric URL
  otel_log_url: # Open Telemetry exporter log URL
  expected_max_roles: # to avoid dos we limited the number of roles, default 4000
  decorate_roles_fetching_all_roles: # default true, will grab all roles from the database and find accumulated roles in that array, if set to false will do multiple queries to the database to find all nested roles for the user
  roles_cached_in_seconds: # if decorate_roles_fetching_all_roles is true, how many seconds will we cache all roles, default is 300, to disable cache set to 0
  max_recursive_group_depth: # if decorate_roles_fetching_all_roles is false, limit how many nested groups to go though, default 2
  validate_user_form: # User validation form, if set, will force all users to be fill out this form in order to login.
  shorttoken_expires_in: # default 5m
  longtoken_expires_in: # default: 365d
  downloadtoken_expires_in: # default: 15m
  personalnoderedtoken_expires_in: # default: 365d
  debug: # Configure logging for the debug plugin
  NO_PROXY: # Set NO_PROXY for all api and agents
  HTTP_PROXY: # Set HTTP_PROXY for all api and agents
  HTTPS_PROXY: # Set HTTPS_PROXY for all api and agents
  agent_NO_PROXY: # Set NO_PROXY for all agents only
  agent_HTTP_PROXY: # Set HTTP_PROXY for all agents only
  agent_HTTPS_PROXY: # Set HTTPS_PROXY for all agents only
  agent_domain_schema: # default is $slug$.domain ( for instance $slug$.app.openiap.io )
  
  # limits:
  #   #   cpu: "1"
  #   #memory: 1Gi
  #   memory: 768Mi
  # requests:
  #   # cpu: "0.02"
  #   memory: 128Mi
  auto_hourly_housekeeping:  # Enable an hourly job, that does basic house keeping, default false
  housekeeping_skip_collections: # Comma seperated list of collections to skip while calculating database usage

  workitem_queue_monitoring_enabled: 
  workitem_queue_monitoring_interval: 

  stripe_force_vat: # When multi_tenant is enabled, force new customers to add VAT information, default false
  stripe_force_checkout: # When multi_tenant is enabled, force users to accept a stripe checkout session for each purchaes, default true
  auto_create_user_from_jwt: # If openflow received an JWT for an unknown user, auto create the user. Used in certain demo setups, default false

  # To use openflow as an webpush server, add your wapid certificate and email here
  wapid_pub: 
  wapid_key: 
  wapid_mail: 
rabbitmq:
  image: rabbitmq:3.8.3-management
  exposed: false
  default_user: admin
  # vm_memory_high_watermark: 1GB
  default_pass:
  resources: {}
  # limits:
  #   #   cpu: "1"
  #   #memory: 1Gi
  #   memory: 1Gi
  # requests:
  #   # cpu: "0.02"
  #   memory: 256Mi
grafana:
  enabled: false
  image: openiap/grafana:1.0.22 # set image used when deploying frafana
  oauth_client_id: application
  oauth_client_secret: secret
  allow_embedding: true # set to true if you want to allow browsers to render Grafana in a <frame>, <iframe>, <embed> or <object>. default is false.
  send_user_header: false # If enabled and user is not anonymous, data proxy will add X-Grafana-User header with username into the request, default is false.
  reporting_enabled: false # sends usage counters to stats.grafana.org every 24 hours.
  oauth_auto_login: true # Set to true to attempt login with OAuth automatically, skipping the login screen.
  openflow_datasource: true # inject openflow data source, this should be set to false after first deploy if you set alert manager credentials
  prometheus_datasource: true # inject prometheus data source
  persistence:
    size: 10Gi
    storageclass:
  smtp:
    enabled: false
    host:
    user:
    password:
    from:
    fromname:
loki:
  enabled: false # require using export.image: otel/opentelemetry-collector-contrib
  image: grafana/loki
  persistence:
    size: 10Gi
    storageclass:
  nodeSelector: {}
prometheus: # deprecated, we use victoriametrics now.
  image: prom/prometheus
  enabled: false
  exposed: false
  persistence:
    size: 10Gi
    storageclass:
  resources: {}
exporter: # open telemetry exporter. This service receive metrics and spans from openrpa/nodered and openrpa robots
  enabled: false # enable setting up the, open telemetry exporter
  exposed: false # expose using IngressRoute so remote nodered and openrpa robots can send data
  type: ClusterIP # set the service type of exporter, default is ClusterIP, set to LoadBalancer to expose as a seperate service with a dedicated it
  loadBalancerIP: # set the load balancer IP if type is set to LoadBalancer
  command: /otelcol # overwrite with /otelcol-contrib if using image: otel/opentelemetry-collector-contrib
  # loglevel: info # debug, info
  # image: otel/opentelemetry-collector:0.30.1
  # image: otel/opentelemetry-collector:0.38.0
  # image: otel/opentelemetry-collector:0.53.0
  image: otel/opentelemetry-collector
  elastic:
    metricsenabled: false
    traceenabled: false
    insecure: true # is the endpoint using TLS or not ?
    insecure_skip_verify: true # whether to skip verifying the certificate or not
    elastic_apm_server_endpoint: 
    elastic_apm_server_authorization: 
    secret_token: 
  opensearch:
    metricsenabled: false
    traceenabled: false
    logsenabled: false
    insecure: true # is the endpoint using TLS or not ?
    insecure_skip_verify: true # whether to skip verifying the certificate or not
    data_prepper_host: 
  kubestatemetrics:
    # image: quay.io/coreos/kube-state-metrics
    image: registry.k8s.io/kube-state-metrics/kube-state-metrics:v2.10.0
    exporterimage: cloudhack/metrics-server-exporter
    enabled: false
    deploy: false
    exporttarget: metrics-server-exporter.kube-system.svc.cluster.local:8000
    kubesystemtarget: kube-state-metrics.kube-system.svc.cluster.local:8080
  resources: {}
  memorylimit:
    enabled: false
    limit_mib: 1500 # 80% of maximum memory up to 2G
    spike_limit_mib: 512 # 25% of limit up to 2G
    check_interval: 5s
jaeger: # for visualizing and optionally also saving all spans, we can use jaeger.
  enabled: false
  collector:
    service:
      grpc:
        port: 4317
      # otlp:
        # grpc:
        #   name: otlp-grpc
        #   port: 4317
        #   # nodePort: 
  exposed: false
  # provisionDataStore: 
  #   cassandra: false
  # storage:
  #   type: elasticsearch
  #   elasticsearch:
  #     scheme: https
  #     host: "opensearch-cluster-master"
  #     port: "9200"
  #     user: admin
  #     password: admin
  #     usePassword: true
  #     cmdlineParams:
  #       es.version: 7
  # tag: 1.22.0
  # agent:
  #   enabled: false
  # collector:
  #   enabled: true
  #   extraEnv:
  #     - name: ES_TLS_ENABLED
  #       value: "true"
  #     - name: ES_TLS_SKIP_HOST_VERIFY
  #       value: "true"  

  # query:
  #   enabled: true
  #   extraEnv:
  #     - name: ES_TLS_ENABLED
  #       value: "true"
  #     - name: ES_TLS_SKIP_HOST_VERIFY
  #       value: "true"  
  #   agentSidecar:
  #     enabled: false
  #   service:
  #     # type: LoadBalancer
  #     port: 80
  #   config: |-
  #     {
  #       "dependencies": {
  #         "dagMaxNumServices": 200,
  #         "menuEnabled": false
  #       },
  #       "menu": [
  #     {
  #       "label": "OpenIAP Resources",
  #       "items": [
  #         {
  #           "label": "OpenFlow",
  #           "url": "https://app.openiap.io/"
  #         },
  #           {
  #           "label": "Support options",
  #           "url": "https://openiap.io/"
  #         }
  #           ]
  #         }
  #       ],
  #       "archiveEnabled": true,
  #       "search": {
  #         "maxLookback": {
  #           "label": "7 Days",
  #           "value": "7d"
  #         },
  #         "maxLimit": 2500
  #       }
  #     }

  # spark:
  #   enabled: false

  # esIndexCleaner:
  #   enabled: false

  # esRollover:
  #   enabled: false

  # esLookback:
  #   enabled: false
zipkin: # for visualizing and optionally also saving all spans, we can use zipkin.
  image: openzipkin/zipkin
  enabled: false
  exposed: false # expose in ingress
  selftracing: false # log spans to self, for troubleshooting zipkin it self
  cassandra: false # persist all data to cassandra, instead of only keeping them temporarily
  javaopts: "-Xms128m -Xmx512m -XX:+ExitOnOutOfMemoryError" # set java memory limits, this should be lower but close to the kubernetes limits.
  resources: {}
  nodeSelector: {}
cassandra:
  enabled: false
  persistence:
    size: 10Gi
    storageclass:
  storagesize: 10Gi
  resources: {}
victoria-metrics-cluster:
  enabled: false
victoriametrics: # for exposing all all metric data for grafana, optionally also saving all metric data, we use victoriametrics
  image: victoriametrics/victoria-metrics
  enabled: false
  exposed: false
  # insertendpoint: http://openflow-victoria-metrics-cluster-vminsert.stats.svc.cluster.local:8480/insert/0/prometheus/
  # selectendpoint: http://openflow-victoria-metrics-cluster-vmselect.stats.svc.cluster.local:8481/select/0/prometheus/
  retentionPeriod: # override default retension of 1 month https://github.com/VictoriaMetrics/VictoriaMetrics#retention
  persistence:
    enabled: false
    size: 100Gi
    storageclass:
  resources: {}
mongodb:
  enabled: true # by setting this to enable a 3 node replicaset wil be deployed and the config updated to use this
  # for this to work, all 5 fields below must be filled
  auth: 
    enabled: false
    adminuser: 
    adminpass: 
    initdb: openflow
    username: 
    password: 
  persistence:
    size: 20Gi
rediscommander:
  image: rediscommander/redis-commander
  enabled: false
  exposed: false
