{{- if and .Values.openflow.license_key (eq .Values.exporter.enabled true) }}
{{- $domain := print (required "domain required!" .Values.domain) "." (required "domainsuffix required!" .Values.domainsuffix) }}
apiVersion: v1
kind: ConfigMap
metadata:
  name: otel-collector-conf
  labels:
    app: opentelemetry
data:
  otel-collector-config: |
    receivers:
      otlp:
        protocols:
          grpc:
          http:
            cors_allowed_origins:
            - http://*
            - https://*
{{- if (eq .Values.exporter.kubestatemetrics.enabled true) }}
      prometheus:
          config:
            scrape_configs:
              # - job_name: 'otel-collector'
              #   scrape_interval: 5s
              #   static_configs:
              #     - targets: ['0.0.0.0:8888']
              # - job_name: k8s
              #   kubernetes_sd_configs:
              #   - role: pod
              #   relabel_configs:
              #   - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scrape]
              #     regex: "true"
              #     action: keep
              #   metric_relabel_configs:
              #   - source_labels: [__name__]
              #     regex: "(request_duration_seconds.*|response_duration_seconds.*)"
              #     action: keep
              - job_name: 'kube-state-collector'
                scrape_interval: 5s
                static_configs:
                  - targets: ['{{ .Values.exporter.kubestatemetrics.exporttarget }}','{{ .Values.exporter.kubestatemetrics.kubesystemtarget }}']
{{- end }}
  {{- if (eq .Values.loki.enabled true) }}
      loki:
        endpoint: http://openflow-loki:3100/loki/api/v1/push
        tenant_id: "example"
        labels:
          resource:
            # Allowing 'container.name' attribute and transform it to 'container_name', which is a valid Loki label name.
            container.name: "container_name"
            # Allowing 'k8s.cluster.name' attribute and transform it to 'k8s_cluster_name', which is a valid Loki label name.
            k8s.cluster.name: "k8s_cluster_name"
          attributes:
            # Allowing 'severity' attribute and not providing a mapping, since the attribute name is a valid Loki label name.
            severity: ""
            http.status_code: "http_status_code" 
        headers:
          "X-Custom-Header": "loki_rocks"
  {{- end }}
    processors:
      batch:
    extensions:
      health_check: {}
      zpages: {}
    exporters:
      jaeger:
        endpoint: jaeger:14250
        insecure: true
{{- if (eq .Values.zipkin.enabled true) }}
      zipkin:
        endpoint: "http://zipkin:9411/api/v2/spans"
        format: proto
{{- end }}
{{- if (.Values.exporter.loglevel)}}
      logging:
       loglevel: {{ .Values.exporter.loglevel }}
{{- end }}
      prometheus:
       endpoint: "0.0.0.0:9464"
      #  namespace: otelcollector
      prometheusremotewrite:
        endpoint: "http://victoriametrics:8428/api/v1/write"
    service:
      extensions: [health_check, zpages]
      pipelines:
        metrics:
{{- if (eq .Values.exporter.kubestatemetrics.enabled true) }}
          receivers: [prometheus,otlp]
{{- else }}
          receivers: [otlp]
{{- end }}
          exporters: [prometheusremotewrite, prometheus]
          processors: []
        traces:
          receivers: [otlp]
          processors: [batch]
{{- if and (eq .Values.jaeger.enabled true) (eq .Values.zipkin.enabled true) }}
          exporters: [jaeger, zipkin]
{{- else if and (eq .Values.jaeger.enabled true) (eq .Values.zipkin.enabled false) }}
          exporters: [jaeger]
{{- else if and (eq .Values.jaeger.enabled false) (eq .Values.zipkin.enabled true) }}
          exporters: [zipkin]
{{- else }}
          exporters: []
{{- end }}
{{- if (eq .Values.loki.enabled true) }}
        logs:
          receivers: [otlp]
          exporters: [ loki ]
{{- end }}
          
#        traces:
#          receivers: [otlp]
#          exporters: [jaeger]
#          exporters: [jaeger,logging]
#          exporters: [prometheus]
#        endpoint: "/api/prom/push"
#        endpoint: "/api/v1/write"
# prometheus:
#     config:
#       scrape_configs:
#         - job_name: 'otel-collector'
#           scrape_interval: 5s
#           static_configs:
#             - targets: [ 'localhost:55681' ]
# https://opentelemetry.io/docs/collector/configuration/#exporters

---
apiVersion: v1
kind: Service
metadata:
  name: otel-collector
  labels:
    app: opentelemetry
spec:
  type: NodePort
  ports:
    - name: otlp # Default endpoint for OpenTelemetry receiver.
      port: 55680
      protocol: TCP
      targetPort: 55680
    - name: jaeger-grpc # Default endpoint for Jaeger gRPC receiver
      port: 14250
    - name: jaeger-thrift-http # Default endpoint for Jaeger HTTP receiver.
      port: 14268
    # - name: zipkin # Default endpoint for Zipkin receiver.
    #   port: 9411
    - name: metrics # Default endpoint for querying metrics.
      port: 8888
    - name: prometheus # Default endpoint for querying metrics.
      port: 9464
    - name: collector # Default endpoint for querying metrics.
      port: 55681
    - name: newport
      port: 4317
  selector:
    app: opentelemetry
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: otel-collector
  labels:
    app: opentelemetry
spec:
  selector:
    matchLabels:
      app: opentelemetry
  minReadySeconds: 5
  progressDeadlineSeconds: 120
  replicas: 1 
  template:
    metadata:
      labels:
        app: opentelemetry
    spec:
      {{- if .Values.nodeSelector }}
      nodeSelector: {{- include "common.tplvalues.render" (dict "value" .Values.nodeSelector "context" $) | nindent 8 }}
      {{- end }}
      containers:
        - command:
            - "/otelcol"
            - "--config=/conf/otel-collector-config.yaml"
            #           Memory Ballast size should be max 1/3 to 1/2 of memory.
            - "--mem-ballast-size-mib=683"
            - "--log-level=DEBUG"
          # image: otel/opentelemetry-collector-dev:latest
          resources:
            {{- toYaml .Values.exporter.resources | nindent 12 }}
          image: {{ default "otel/opentelemetry-collector" .Values.exporter.image | quote }}
          name: otel-collector
          ports:
            - containerPort: 55679 # Default endpoint for ZPages.
            - containerPort: 55680 # Default endpoint for OpenTelemetry receiver.
            - containerPort: 14250 # Default endpoint for Jaeger HTTP receiver.
            - containerPort: 14268 # Default endpoint for Jaeger HTTP receiver.
            # - containerPort: 9411 # Default endpoint for Zipkin receiver.
            - containerPort: 8888 # Default endpoint for querying metrics.
            - containerPort: 9464 # Prometheus exporter metrics
            - containerPort: 55681 # Collector port
            - containerPort: 4317 # new port
          volumeMounts:
            - name: otel-collector-config-vol
              mountPath: /conf
          #        - name: otel-collector-secrets
          #          mountPath: /secrets
          livenessProbe:
            httpGet:
              path: /
              port: 13133 # Health Check extension default port.
          readinessProbe:
            httpGet:
              path: /
              port: 13133 # Health Check extension default port.
      volumes:
        - configMap:
            name: otel-collector-conf
            items:
              - key: otel-collector-config
                path: otel-collector-config.yaml
          name: otel-collector-config-vol
#        - secret:
#            name: otel-collector-secrets
#            items:
#              - key: cert.pem
#                path: cert.pem
#              - key: key.pem
#                path: key.pem
---
  {{- if (eq .Values.exporter.exposed true) }}
apiVersion: traefik.containo.us/v1alpha1
kind: IngressRoute
metadata:
  name: ingressroute.otel
spec:
  entryPoints:
    - web
    - websecure
  routes:
    - match: Host(`otel.{{$domain}}`)
      kind: Rule
      services:
        - name: otel-collector
          port: 4317
          scheme: h2c
  {{- end }}
{{- end }}



